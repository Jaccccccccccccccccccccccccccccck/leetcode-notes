qemu-rio项目
项目简介：联合模拟器QEMU和语分析工具Dynamorio，使用QEMU插桩程序代码，使用Dynamorio进行分析
主要工作栈：C、C++
工作内容：
· 共享内存及信息传递的设计与开发
· 开发耦合版本减少进程间通信开销
· 函数调用分析工具、基本块热点分析工具接入与二次开发 

### 简单介绍项目
qemu是一个使用动态二进制翻译技术进行跨平台模拟的工具，支持用户模式和系统模式，它将guest代码指令翻译成IR，然后再将IR翻译成host指令；本项目主要用来基本块级别的插桩；
dynamorio是一个二进制分析平台，其自带了多种二进制分析工具，比较有代表性的有cache simulation、指令分类统计、call graph等
的内容
DynamoRIO的的缺点：
- 指令集支持的少，仅支持x86、ARM
- 仅支持用户级别程序的插桩，并不支持系统级别的指令
- 原有支持的功能包括：指令类型分析、call graph分析、cache行为模拟

### 工作内容
- qemu内的插桩，在qemu把源代码翻译成ir时，进行插桩，把指令信息、访存信息外传
- 通信模块，使用多生产者、单消费者的ringbuffer共享内存，进行进程间通信
- Rio原有的插桩模块的分离，只保留分析模块
- 运行在qemu全系统的控制传输程序，控制传输开始和结束，控制监听程序的用户程序命令，指令监听的指令数量等
- 在原有的Dynamorio分析工具做了拓展

### 共享内存中的ringbuffer交互
https://juejin.cn/post/6844903753804431374
ringbuffer使用一个数组存储数据，使用两个指针分别指向
仅有一个生产者和一个消费者的时候无需额外的同步机制

### 缓存一致性问题（一致性问题,coherence）
https://www.cs.utexas.edu/~bornholt/post/memory-models.html

**缓存一致性保证了多个处理器看到的存储器内容是一致的**
问题定义：多个不同处理器对同一位置的数据有各自的缓存副本，它们可能会在同一位置看到两个不同值。
问题解决方案：**写入失效协议**，一个处理器对地址X执行写入操作后，其他处理器的副本X会失效；同样的解决方案是**写入更新协议**，也叫写入广播

### 存储器连贯性模型（memory model，内存模型，连贯性问题,consistency）
问题定义：存储器有着与直观上顺序访存不一样的行为
最简单的模型称为：**顺序连贯性模型**，单个线程中的事件按它们编写的顺序发生，缺点是性能很差，在此模型上，写入操作不能进入写入缓冲区，而是直接进行写入失效

**宽松的连贯性模型**：允许乱序执行读取和写入操作，但使用同步操作进行排序，一个比较出名的宽松连贯性模型为完全存储排序（TSO，total store ordering），仅保证存储的有序性，其产生乱序的原因是引入了写入缓冲区
**解决宽松内存模型引入的同步问题的方法**：使用内存屏障（barrier，or fence），内存屏障用于控制宽松的内存模型。屏障指令强制它之前的所有内存操作在它之后的任何内存操作可以开始之前完成。也就是说，屏障指令有效地恢复了程序执行中特定点的顺序一致性。
**编写程序时**：使用标准的同步库，编写同步程序

### volatile关键字使用
https://stackoverflow.com/questions/2484980/why-is-volatile-not-considered-useful-in-multithreaded-c-or-c-programming
volatile关键字主要用于
- 防止**编译器**对源代码中的对象进行优化，当变量声明为volatile时，**编译器**生成代码确保每次访问变量时读取或写入真实值，并不适用缓存或优化的值。
- 也保证了多个volatile变量读写的顺序性，但并不保证非volatile变量的顺序
  
仅用volatile在同步中是没有必要的，因为它不能阻止编译器和CPU的重排序，需要配合barrier使用，但没有必要，barrier会提供更好的语义，可以直接使用
在关键字设计之初，是为了用来操作IO寄存器和内存映射的硬件

### 为什么volatile关键字在ring buffer中被使用
因为存在宽松的内存模型，导致在ring buffer中单个线程对另外一个线程的修改可能存在感知延迟
https://www.prepbytes.com/blog/c-programming/volatile-keyword-in-c/

### 进程通信方法
根据**是否需要操作系统的辅助**的分类：操作系统辅助的进程间通信，需要操作系统提供的通信接口，把**发送者**进程的内容copy到内核内存空间，后将内容发送到**接受者**的内存空间，这样设计有管道、消息队列
- 管道：**单向信息流**；分为匿名管道和命名管道，匿名管道仅可以在兄弟进程和父子进程之间使用，命名管道没有这个约束；管道以**文件**的形式读写，数据抽象为**字节流**；管道中信息被保存在内核内存中；
- 消息队列：**多进程通信！**，数据抽象为**消息**，在内核中的存在形式是链表队列，与管道一样在进程间通信时需要内核态和用户态上下文切换和内容copy；消息队列独立于发送和接受进程，进程终止时，消息队列内容不会被删除
- 信号量：**多进程通信**，进程间同步方式，工作机制可以简单理解为计数器，申请访问临界区资源时进行P操作，将计数器-1，当计数器减到0时，说明临界区已经没有资源了，申请的进程需要等待，直到计数器大于0；当离开临界区是进行V操作将计数器+1
- 共享内存：**多进程通信**，将两个进程地址空间的一部分映射到同一个物理地址，并通过这一共享的内存空间进行通信；本身并不提供同步机制，需要额外引入其他的同步，例如信号量；
- 信号：**多进程通信**，拥有**中断**类似功能的**单向**事件通知能力，接受信号的进程不需要阻塞等待某个信号到来，而是内核主动将进程切换到对应的处理函数中；数据抽象为事件编号
- 嵌套字：既可以用于本地，又可以跨网络使用的通信机制，根据使用地址分为两种类型：1.基于文件作为地址的嵌套字，2.基于IP地址和端口作为地址的嵌套字；嵌套字进程间通信可以使用不同的协议，一类是**传输控制协议**（TCP），可靠性好，有数据重传、数据顺序维护等功能，另一类是**用户数据报协议**（UDP），传输性能会更好

### 进程同步方法
- 互斥锁：最常见的线程同步方式，在使用一个共享资源前加锁，使用后解锁
  - 分类：使用CAS实现的自旋锁，使用FAA实现的排号自旋锁
  - 优点：使用简单
  - 缺点：自旋锁不能保证获得锁的顺序，即**不公平**，排号自旋锁解决了这一问题；在获取锁的时候会进行忙等待
  - **在Pthread库中mutex不是互斥锁，在没有获得锁的时候不会忙等待，会把当前线程进入睡眠**
- 条件变量：为了解决获取互斥锁后，某些条件没有满足导致线程拿到锁依旧在等待某些条件导致**忙等待**的问题，条件变量提供了**挂起/唤醒**机制，且必须**与互斥锁一起使用**
  - https://stackoverflow.com/questions/4742196/advantages-of-using-condition-variables-over-mutex
  - 优点：解决了互斥锁在访问共享资源的时候的条件不满足引起的忙等待（busy looping）
  - 提供了两个接口，**cond_wait**用来挂起当前已经拿到锁但没有满足条件的线程,**cond_signal**用于唤醒等待该条件变量的线程
- 信号量：使用计数器表示可以使用的共享资源数量，与互斥锁仅能一个线程进入临界区不同，信号量可以允许多个线程进入临界区
- 读写锁：当一些线程仅需要读取而非修改共享资源时，多个读线程不需要互斥性。与互斥锁相比，在多个读线程时有更好的性能。针对读线程与写线程分别提供了不同的lock和unlock操作；设想一种情况：已经有一个读线程在临界区，此时有一个写线程和一个读线程同时申请进入临界区，在选择的偏好中分为**偏向读者的读写锁**和**偏向写者的读写锁**

### 同步带来的问题

#### 死锁
定义：一组线程都在等在组内其他线程释放资源从而造成的无限等待
死锁产生的原因：
- 互斥访问
- 持有并等待
- 资源非抢占
- 循环等待
还有一种产生死锁的特殊情况是：**中断处理流程中使用互斥锁**，产生的情况分为以下两种
- 中断上下文中使用到了其他线程已经锁定的互斥锁
- 中断嵌套中两个中断互相持有锁，并等待对方的锁释放

死锁预防：
- 避免互斥访问：避免互斥访问的一个例子为：所有对临界区访问都通过一个代理线程来访问，缺点为大部分应用程序不容易修改成此模式
- 不允许持有并等待：要求线程在进入临界区前，一次性申请所有的资源，缺点是资源竞争程度高时，进入申请-释放的循环，造成资源利用率低，甚至饥饿情况
- 允许资源被强占：线程已经获取的锁可以被抢占掉，缺点是需要回滚拿到部分锁之后进行的操作，并在锁释放掉后进行恢复
- 避免循环等待：要求线程必须按照一定顺序来获取资源。
  
**银行家算法**：避免死锁的算法
